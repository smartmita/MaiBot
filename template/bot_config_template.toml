[inner]
version = "2.0.0.11"

#----以下是给开发人员阅读的，如果你只是部署了麦麦，不需要阅读----
#如果你想要修改配置文件，请在修改后将version的值进行变更
#如果新增项目，请阅读src/config/official_configs.py中的说明
#
# 版本格式：主版本号.次版本号.修订号，版本号递增规则如下：
#     主版本号：当你做了不兼容的 API 修改，
#     次版本号：当你做了向下兼容的功能性新增，
#     修订号：当你做了向下兼容的问题修正。
# 先行版本号及版本编译信息可以加到"主版本号.次版本号.修订号"的后面，作为延伸。
#----以上是给开发人员阅读的，如果你只是部署了麦麦，不需要阅读----

[bot]
qq_account = 1145141919810
nickname = "麦麦"
alias_names = ["麦叠", "牢麦"] #该选项还在调试中，暂时未生效

[chat_target]
talk_allowed_groups = [
    123,
    123,
]  #可以回复消息的群号码
talk_frequency_down = []  #降低回复频率的群号码
ban_user_id = []  #禁止回复和读取消息的QQ号

[personality]
personality_core = "用一句话或几句话描述人格的核心特点" # 想写多少写多少
personality_sides = [
    "用一句话或几句话描述人格的一些细节",
    "用一句话或几句话描述人格的一些细节",
    "用一句话或几句话描述人格的一些细节",
    "用一句话或几句话描述人格的一些细节",
    "用一句话或几句话描述人格的一些细节",
]# 条数任意，不能为0
personality_detail_level = 0 # 人设消息注入 prompt 详细等级 (0: 采用默认配置, 1: 核心/随机细节, 2: 核心+随机侧面/全部细节, 3: 全部)

# 表达方式
expression_style = "描述bot说话的表达风格，表达习惯"
enable_expression_learner = true  # 是否启用新发言习惯注入，关闭则启用旧方法

[identity] #アイデンティティがない 生まれないらららら
# 身份特点
identity_detail = [
    "身份特点",
    "身份特点",
]# 条数任意，不能为0

#外貌特征
age = 18 # 年龄 单位岁
gender = "女" # 性别
height = "170" # 身高（单位cm）
weight = "50" # 体重（单位kg）
appearance = "用一句或几句话描述外貌特征" # 外貌特征

[schedule]
enable = true # 是否启用日程表
prompt_schedule_gen = "用几句话描述描述性格特点或行动规律，这个特征会用来生成日程表"
schedule_doing_update_interval = 900 # 日程表更新间隔 单位秒
time_zone = "Asia/Shanghai" # 给你的机器人设置时区，可以解决运行电脑时区和国内时区不同的情况，或者模拟国外留学生日程
knowledge_relevance_threshold = 0.38 # 日程表检索知识库相关性阈值
max_knowledge_items_for_schedule_prompt = 5 # 最终日程注入知识库条数上限

[platforms] # 必填项目，填写每个平台适配器提供的链接
qq="http://127.0.0.1:18002/api/message"

[chat] #聊天通用设置
allow_focus_mode = false # 是否允许专注聊天状态
# 是否启用heart_flowC(HFC)模式
# 启用后bot会自主选择进入heart_flowC模式（持续一段时间），进行主动的观察和回复，并给出回复，比较消耗token
base_normal_chat_num = 999 # 最多允许多少个群进行普通聊天
base_focused_chat_num = 4 # 最多允许多少个群进行专注聊天
allow_remove_duplicates = true # 是否开启心流去重（如果发现心流截断问题严重可尝试关闭）

observation_context_size = 15 # 观察到的最长上下文大小,建议15，太短太长都会导致脑袋尖尖
message_buffer = true # 启用消息缓冲器？启用此项以解决消息的拆分问题，但会使bot的回复延迟

enable_llm_judgment_for_chat_to_focus = true # 是否启用LLM判断CHAT状态的子心流是否应该进入专注聊天
probability_for_llm_judgment_chat_to_focus = 0.6 # 当启用LLM判断CHAT到FOCUSED时，有多大概率实际执行LLM判断流程，默认0.6为60%

# 以下是消息过滤，可以根据规则过滤特定消息，将不会读取这些消息
ban_words = [
    # "403","张三"
    ]

ban_msgs_regex = [
    # 需要过滤的消息（原始消息）匹配的正则表达式，匹配到的消息将被过滤（支持CQ码），若不了解正则表达式请勿修改
    #"https?://[^\\s]+", # 匹配https链接
    #"\\d{4}-\\d{2}-\\d{2}", # 匹配日期
    # "\\[CQ:at,qq=\\d+\\]" # 匹配@
]

[normal_chat] #普通聊天
#一般回复参数
reasoning_model_probability = 0.3 # bot生成消息时选择推理模型的概率（与之相对的，普通模型的概率为1 - reasoning_model_probability）

emoji_chance = 0.2 # bot一般回复时使用表情包的概率，设置为1让bot自己决定发不发
thinking_timeout = 120 # bot最长思考时间，超过这个时间的思考会放弃（往往是api反应太慢）

willing_mode = "classical" # 回复意愿模式 —— 经典模式：classical，mxp模式：mxp，自定义模式：custom（需要你自己实现）
response_willing_amplifier = 1 # bot回复意愿放大系数，一般为1，多半需要下调
response_interested_rate_amplifier = 1 # bot回复兴趣度放大系数,听到记忆里的内容时放大系数，多半需要下调
down_frequency_rate = 3 # 降低回复频率的群组回复意愿降低系数 除法
emoji_response_penalty = 0 # 表情包回复惩罚系数，设为0为不回复单个表情包，减少单独回复表情包的概率
mentioned_bot_inevitable_reply = false # 提及 bot 必然回复
at_bot_inevitable_reply = false # @bot 必然回复

[focus_chat] #专注聊天
reply_trigger_threshold = 3.0 # 专注聊天触发阈值，越低越容易进入专注聊天
default_decay_rate_per_second = 0.98 # 默认衰减率，越大衰减越快，越高越难进入专注聊天
consecutive_no_reply_threshold = 3 # 连续不回复的阈值，越低越容易结束专注聊天

# 以下选项暂时无效
compressed_length = 5 # 不能大于observation_context_size,心流上下文压缩的最短压缩长度，超过心流观察到的上下文长度，会压缩，最短压缩长度为5
compress_length_limit = 5 #最多压缩份数，超过该数值的压缩上下文会被删除

[dynamic_replan]
enable = true # 是否启用动态重新规划机制

[dynamic_replan.probabilities] # 需要启用动态重新规划机制
"1" = 0.05    # 收到1条新消息时，5%的概率重新规划
"2" = 0.10    # 收到2条新消息时，10%的概率重新规划
"3+" = 0.50   # 收到3条或更多新消息时，50%的概率重新规划


[emoji]
max_reg_num = 40 # 表情包最大注册数量
do_replace = true # 开启则在达到最大数量时删除（替换）表情包，关闭则达到最大数量时不会继续收集表情包
check_interval = 120 # 检查表情包（注册，破损，删除）的时间间隔(分钟)
save_pic = false # 是否保存图片
cache_emoji = true # 是否缓存表情包
steal_emoji = true # 是否偷取表情包，让bot可以发送她保存的这些表情包
content_filtration = false  # 是否启用表情包过滤，只有符合该要求的表情包才会被保存
filtration_prompt = "符合公序良俗" # 表情包过滤要求，只有符合该要求的表情包才会被保存

[memory]
memory_build_interval = 2000 # 记忆构建间隔 单位秒   间隔越低，bot学习越多，但是冗余信息也会增多
memory_build_distribution = [6.0, 3.0, 0.6, 32.0, 12.0, 0.4] # 记忆构建分布，参数：分布1均值，标准差，权重，分布2均值，标准差，权重
memory_build_sample_num = 8 # 采样数量，数值越高记忆采样次数越多
memory_build_sample_length = 40 # 采样长度，数值越高一段记忆内容越丰富
memory_compress_rate = 0.1 # 记忆压缩率 控制记忆精简程度 建议保持默认,调高可以获得更多信息，但是冗余信息也会增多

forget_memory_interval = 1000 # 记忆遗忘间隔 单位秒   间隔越低，bot遗忘越频繁，记忆更精简，但更难学习
memory_forget_time = 24 #多长时间后的记忆会被遗忘 单位小时
memory_forget_percentage = 0.01 # 记忆遗忘比例 控制记忆遗忘程度 越大遗忘越多 建议保持默认

consolidate_memory_interval = 1000 # 记忆整合间隔 单位秒   间隔越低，麦麦整合越频繁，记忆更精简
consolidation_similarity_threshold = 0.7 # 相似度阈值
consolidation_check_percentage = 0.01 # 检查节点比例

#不希望记忆的词，已经记忆的不会受到影响
memory_ban_words = [ "表情包", "图片", "回复", "聊天记录" ]

long_message_auto_truncate = true # HFC 模式过长消息自动截断，防止他人 prompt 恶意注入，减少token消耗，但可能损失图片/长文信息，按需选择状态（默认开启）

[mood]
mood_update_interval = 1.0 # 情绪更新间隔 单位秒
mood_decay_rate = 0.95 # 情绪衰减率
mood_intensity_factor = 1.0 # 情绪强度因子

[keyword_reaction] # 针对某个关键词作出反应
enable = true  # 关键词反应功能的总开关

[[keyword_reaction.rules]] # 如果想要新增多个关键词，直接复制本条，修改keywords和reaction即可
enable = true # 是否启用此条（为了人类在未来AI战争能更好地识别AI（bushi），默认开启）
keywords = ["人机", "bot", "机器", "入机", "robot", "机器人","ai","AI"] # 会触发反应的关键词
reaction = "有人说你是人机或者机器人，否定这一事实，攻击或反问他。注意，只有认为你是机器人才回复，否则不要否认" # 触发之后添加的提示词

[[keyword_reaction.rules]] # 就像这样复制
enable = false # 仅作示例，不会触发
keywords = ["测试关键词回复","test",""]
reaction = "回答“测试成功”" # 修复错误的引号

[[keyword_reaction.rules]] # 使用正则表达式匹配句式
enable = false # 仅作示例，不会触发
regex = ["^(?P<n>\\S{1,20})是这样的$"] # 将匹配到的词汇命名为n，反应中对应的[n]会被替换为匹配到的内容，若不了解正则表达式请勿编写
reaction = "请按照以下模板造句：[n]是这样的，xx只要xx就可以，可是[n]要考虑的事情就很多了，比如什么时候xx，什么时候xx，什么时候xx。（请自由发挥替换xx部分，只需保持句式结构，同时表达一种将[n]过度重视的反讽意味）"

[chinese_typo]
enable = true # 是否启用中文错别字生成器
error_rate=0.01 # 单字替换概率
min_freq=9 # 最小字频阈值
tone_error_rate=0.1 # 声调错误概率
word_replace_rate=0.006 # 整词替换概率

[response_splitter]
enable = true # 是否启用回复分割器
max_length = 256 # 回复允许的最大长度
max_sentence_num = 4 # 回复允许的最大句子数
enable_kaomoji_protection = false # 是否启用颜文字保护

[telemetry] # 关掉它
enable = false

[experimental] #实验性功能
enable_Legacy_HFC = false  # 是否启用旧 HFC 处理器
enable_friend_chat = true # 是否启用好友聊天
enable_friend_whitelist = true # 是否启用好友聊天白名单
talk_allowed_private = [] # 可以回复消息的QQ号
api_polling_max_retries = 3  # 神秘小功能
enable_always_relative_history = false # 聊天记录总是使用 relative 模式
force_rethink_tool_list = ["search_knowledge", "get_memory", "lpmm_search_knowledge"] # 可配置：子心流在调用这些工具后不会进入决策，而是进入第二轮思考，留空为不会进入第二轮思考
enable_gender_marking_tool = true # 是否使用性别标记工具和显示用户性别

[profile]
profile_system_enabled = true  # 侧写系统总开关

# 绰号模块
enable_sobriquet_mapping = false  # 绰号映射功能总开关（默认关闭，建议关闭）
max_sobriquets_in_prompt = 10  # Prompt 中最多注入的绰号数量（防止token数量爆炸）
sobriquet_probability_smoothing = 1  # 绰号加权随机选择的平滑因子
sobriquet_queue_max_size = 100  # 绰号处理队列最大容量
sobriquet_process_sleep_interval = 5  # 绰号处理进程休眠间隔（秒），不建议超过5，否则大概率导致优雅结束过程中超时
sobriquet_analysis_history_limit = 30  # 绰号处理可见最大上下文
sobriquet_analysis_probability = 0.1  # 绰号随机概率命中，该值越大，绰号分析越频繁
min_sobriquet_strength_for_prompt_injection = 10  # 绰号应用最低映射强度阈值
sobriquet_event_decay_value = 0.1  # 绰号映射强度自然衰减因子，衰减因子应当大于等于 0 ，减法，0 为不自然衰减
unreliable_sobriquet_decay_factor = 0.1  # 绰号不可靠映射强度衰减因子，衰减因子必须在 [0, 1] 之间，乘法，1 为不启用，0 为不可靠直接清零（可能存在llm误判，因此需要让llm拥有一定的自纠正能力）
reliable_mapping_strength_increment = 5.0  # 绰号可靠映射强度增量

[pfc]
enable = true # 是否启用PFC聊天，该功能仅作用于私聊，与回复模式独立
pfc_message_buffer_size = 2  # PFC 聊天消息缓冲数量，有利于使聊天节奏更加紧凑流畅，请根据实际 LLM 响应速度进行调整，默认2条
pfc_recent_history_display_count = 18  # PFC 对话最大可见上下文

# pfc 检查器
enable_pfc_reply_checker = true # 是否启用 PFC 的回复检查器
pfc_max_reply_attempts = 3  # 发言最多尝试次数
pfc_max_chat_history_for_checker = 30  # checker聊天记录最大可见上文长度

# pfc 情绪
pfc_emotion_update_intensity = 0.6  # 情绪更新强度
pfc_emotion_history_count = 5  # 情绪更新最大可见上下文长度

# pfc 关系
pfc_relationship_incremental_interval = 10  # 关系值增值强度
pfc_relationship_incremental_msg_count = 10  # 会话中，关系值判断最大可见上下文
pfc_relationship_incremental_default_change = 1.0  # 会话中，关系值默认更新值（当 llm 返回错误时默认采用该值）
pfc_relationship_incremental_max_change = 5.0  # 会话中，关系值最大可变值
pfc_relationship_final_msg_count = 30  # 会话结束时，关系值判断最大可见上下文
pfc_relationship_final_default_change =5.0  # 会话结束时，关系值默认更新值
pfc_relationship_final_max_change = 50.0  # 会话结束时，关系值最大可变值

# pfc 聊天记录
pfc_historical_fallback_exclude_seconds = 45 # pfc 翻看聊天记录排除最近时长

# pfc 主动对话
enable_idle_chat = true # 是否启用 pfc 主动发言
idle_check_interval = 10  # 检查间隔，10分钟检查一次
min_cooldown = 7200      # 最短冷却时间，2小时 (7200秒)
max_cooldown = 18000     # 最长冷却时间，5小时 (18000秒)


[model]

# 下面是最复杂的部分，涉及到每个模型的配置
# 模型若使用硅基流动则不需要更改，否则需要自己填写（注意也要填写.env的内容）
# name 是模型的名称，需要去对应供应商获取
# provider 是模型的供应商
# temp 是模型的温度（通常0~1），低温稳定性高，高温随机性高，每个模型对温度的敏感度都不同，如果不了解建议默认
# max_tokens 为模型的最大输出长度（包括思维链）
# 关于max_tokens再说一句，模型不会因为你设定的max_tokens而限制自己的输出长度，只会在达到限制后直接截断，且不返回内容
# pri_in/pri_out分别对应了模型输入和输出的价格，以M(每百万token/元)统计，可以为0或乱写，但不能没有

[model.reasoning] # 一般聊天模式的推理回复模型
name = "Pro/deepseek-ai/DeepSeek-R1"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 4096
pri_in = 1.0
pri_out = 4.0

[model.normal] # 回复模型 专注和一般聊天模式共用的回复模型
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 4096
pri_in = 2
pri_out = 8

[model.topic_judge] #主题判断模型：建议使用qwen2.5 7b
name = "Pro/Qwen/Qwen2.5-7B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 0.35
pri_out = 0.35

[model.summary] #概括模型，建议使用qwen2.5 32b 及以上
name = "Qwen/Qwen2.5-32B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 1.26
pri_out = 1.26

[model.vlm] # 图像识别模型，负责所有图片、表情包的具体识别(需要有视觉能力)
name = "Pro/Qwen/Qwen2.5-VL-7B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 4096
pri_in = 0.35
pri_out = 0.35

[model.emoji_checker] # 表情包审核模型
name = "Pro/Qwen/Qwen2.5-VL-7B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 0.35
pri_out = 0.35

[model.emoji_replacement_decider] # 表情包删除、替换决策模型
name = "Pro/Qwen/Qwen2.5-VL-7B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 0.35
pri_out = 0.35

[model.emotion_judge] # 表情包情绪标签识别模型(需要有视觉能力)
name = "Pro/Qwen/Qwen2.5-VL-7B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 1024
pri_in = 0.35
pri_out = 0.35

[model.heartflow] # 用于控制bot是否参与聊天的模型
name = "Qwen/Qwen2.5-32B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 1024
pri_in = 1.26
pri_out = 1.26

[model.observation] # 观察模型，压缩聊天内容，建议用免费的
# name = "Pro/Qwen/Qwen2.5-7B-Instruct"
name = "Qwen/Qwen2.5-7B-Instruct"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 1024
pri_in = 0
pri_out = 0

[model.sub_heartflow] # 心流：bot的大脑，认真水群时负责生成bot的内心想法，需要强大模型，且必须有工具调用能力
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 65536
pri_in = 2
pri_out = 8

[model.plan] # 决策：认真水群时,负责决定bot该不该回复，要不要@某人，要不要继续聊等
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 1024
pri_in = 2
pri_out = 8

[model.embedding] # 嵌入模型
name = "BAAI/bge-m3"
provider = "SILICONFLOW"
pri_in = 0
pri_out = 0

[model.pfc_action_planner] # PFC决策模型：私聊时，负责决策bot的下一步行动
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 1024
pri_in = 2
pri_out = 8

[model.pfc_chat] # PFC聊天模型：具体聊天消息生成
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 2
pri_out = 8

[model.think_goal] # 目标思考模型，负责思考对话目标（暂时只适用PFC）
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 2
pri_out = 8

[model.idle_chat] # 主动发起对话生成模型（暂时只适用PFC）
name = "Pro/deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 2
pri_out = 8

[model.sobriquet_mapping] # 绰号映射生成模型（如果开启）
name = "Qwen/Qwen2.5-32B-Instruct"
provider = "SILICONFLOW"
temp = 0.2
max_tokens = 2048
pri_in = 1.26
pri_out = 1.26

[model.schedule_initial_generator] # 初始日程模型
name = "deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 8192
pri_in = 2
pri_out = 8

[model.schedule_keyword_extractor] # 日程关键词提取模型
name = "Qwen/Qwen2.5-32B-Instruct"
provider = "SILICONFLOW"
temp = 0.5
max_tokens = 1024
pri_in = 1.26
pri_out = 1.26

[model.schedule_refiner] # 最终日程模型（需要望强大模型）
name = "deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 8192
pri_in = 2
pri_out = 8

[model.schedule_current_activity] # 在干嘛模型，负责bot当前正在做的事
name = "deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 4096
pri_in = 2
pri_out = 8

[model.PFC_relationship_eval] # PFC 关系评估模型
name = "deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.4
max_tokens = 512
pri_in = 2
pri_out = 8

[model.learner] # bot学习表达方式的模型
name = "deepseek-ai/DeepSeek-V3"
provider = "SILICONFLOW"
temp = 0.3
max_tokens = 512
pri_in = 2
pri_out = 8



#以下模型暂时没有使用！！
#以下模型暂时没有使用！！
#以下模型暂时没有使用！！
#以下模型暂时没有使用！！
#以下模型暂时没有使用！！

[model.tool_use] #工具调用模型，需要使用支持工具调用的模型，建议使用qwen2.5 32b
name = "Qwen/Qwen2.5-32B-Instruct"
provider = "SILICONFLOW"
pri_in = 1.26
pri_out = 1.26